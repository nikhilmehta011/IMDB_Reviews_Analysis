{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes from Scratch for Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].map( {'negative':0, 'positive':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing <br><br />\n",
    "def remove_html(text):\n",
    "    html = re.compile(r\"<.*?>\")\n",
    "    return html.sub(r\" \", text)\n",
    "\n",
    "df['review'] = df['review'].map(lambda x: remove_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "df['review'] = df['review'].map(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation\n",
    "def remove_punct(text):\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "df['review'] = df['review'].map(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting into Lowercase\n",
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_tokens(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "df['review'] = df['review'].map(lambda x: review_tokens(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_reviews(result, reviews, sentiments):      # {(word, sentiment): frequency}\n",
    "    '''\n",
    "    Input:\n",
    "        result: a dictionary that will be used to map each pair to its frequency\n",
    "        reviews: a list of reviews\n",
    "        ys: a list corresponding to the sentiment of each review (either 0 or 1)\n",
    "    Output:\n",
    "        result: a dictionary mapping each pair to its frequency\n",
    "    '''\n",
    "    for sentiment, review in zip(sentiments, reviews):\n",
    "        for word in review:\n",
    "            \n",
    "            pair = (word,sentiment)\n",
    "\n",
    "            if pair in result:\n",
    "                result[pair] += 1\n",
    "\n",
    "            else:\n",
    "                result[pair] = 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(result, word, label):\n",
    "    '''\n",
    "    Input:\n",
    "        result: a dictionary with the frequency of each pair (or tuple)\n",
    "        word: the word to look up\n",
    "        label: the label corresponding to the word\n",
    "    Output:\n",
    "        n: the number of times the word with its corresponding label appears.\n",
    "    '''\n",
    "    n = 0  # freqs.get((word, label), 0)\n",
    "\n",
    "    pair = (word, label)\n",
    "    if (pair in freqs):\n",
    "        n = freqs[pair]\n",
    "\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = {}\n",
    "a = count_reviews(freqs, df['review'], df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('one', 1): 26293,\n",
       " ('reviewers', 1): 225,\n",
       " ('mentioned', 1): 489,\n",
       " ('watching', 1): 3769,\n",
       " ('1', 1): 762,\n",
       " ('oz', 1): 179,\n",
       " ('episode', 1): 1900,\n",
       " ('hooked', 1): 216,\n",
       " ('right', 1): 3239,\n",
       " ('exactly', 1): 915,\n",
       " ('happened', 1): 907,\n",
       " ('me', 1): 2664,\n",
       " ('first', 1): 8989,\n",
       " ('thing', 1): 3344,\n",
       " ('struck', 1): 162,\n",
       " ('brutality', 1): 92,\n",
       " ('unflinching', 1): 26,\n",
       " ('scenes', 1): 4828,\n",
       " ('violence', 1): 1014,\n",
       " ('set', 1): 2331,\n",
       " ('word', 1): 770,\n",
       " ('go', 1): 4607,\n",
       " ('trust', 1): 306,\n",
       " ('show', 1): 6517,\n",
       " ('faint', 1): 39,\n",
       " ('hearted', 1): 81,\n",
       " ('timid', 1): 32,\n",
       " ('pulls', 1): 243,\n",
       " ('punches', 1): 68,\n",
       " ('regards', 1): 85,\n",
       " ('drugs', 1): 362,\n",
       " ('sex', 1): 1258,\n",
       " ('hardcore', 1): 120,\n",
       " ('classic', 1): 2311,\n",
       " ('use', 1): 1698,\n",
       " ('called', 1): 1144,\n",
       " ('nickname', 1): 31,\n",
       " ('given', 1): 1646,\n",
       " ('oswald', 1): 23,\n",
       " ('maximum', 1): 47,\n",
       " ('security', 1): 152,\n",
       " ('state', 1): 519,\n",
       " ('penitentary', 1): 2,\n",
       " ('focuses', 1): 230,\n",
       " ('mainly', 1): 415,\n",
       " ('emerald', 1): 10,\n",
       " ('city', 1): 1446,\n",
       " ('experimental', 1): 90,\n",
       " ('section', 1): 188,\n",
       " ('prison', 1): 482,\n",
       " ('cells', 1): 30,\n",
       " ('glass', 1): 176,\n",
       " ('fronts', 1): 19,\n",
       " ('face', 1): 1502,\n",
       " ('inwards', 1): 1,\n",
       " ('privacy', 1): 15,\n",
       " ('high', 1): 1915,\n",
       " ('agenda', 1): 61,\n",
       " ('em', 1): 132,\n",
       " ('home', 1): 2037,\n",
       " ('manyaryans', 1): 1,\n",
       " ('muslims', 1): 32,\n",
       " ('gangstas', 1): 3,\n",
       " ('latinos', 1): 11,\n",
       " ('christians', 1): 43,\n",
       " ('italians', 1): 40,\n",
       " ('irish', 1): 216,\n",
       " ('moreso', 1): 15,\n",
       " ('scuffles', 1): 1,\n",
       " ('death', 1): 2090,\n",
       " ('stares', 1): 23,\n",
       " ('dodgy', 1): 29,\n",
       " ('dealings', 1): 21,\n",
       " ('shady', 1): 43,\n",
       " ('agreements', 1): 5,\n",
       " ('never', 1): 6291,\n",
       " ('far', 1): 2563,\n",
       " ('away', 1): 2577,\n",
       " ('would', 1): 10383,\n",
       " ('say', 1): 4823,\n",
       " ('main', 1): 2123,\n",
       " ('appeal', 1): 387,\n",
       " ('due', 1): 947,\n",
       " ('fact', 1): 3179,\n",
       " ('goes', 1): 2253,\n",
       " ('shows', 1): 3019,\n",
       " ('dare', 1): 145,\n",
       " ('forget', 1): 768,\n",
       " ('pretty', 1): 2971,\n",
       " ('pictures', 1): 501,\n",
       " ('painted', 1): 94,\n",
       " ('mainstream', 1): 246,\n",
       " ('audiences', 1): 581,\n",
       " ('charm', 1): 465,\n",
       " ('romanceoz', 1): 1,\n",
       " ('mess', 1): 192,\n",
       " ('around', 1): 3246,\n",
       " ('ever', 1): 5311,\n",
       " ('saw', 1): 3448,\n",
       " ('nasty', 1): 285,\n",
       " ('surreal', 1): 310,\n",
       " ('ready', 1): 336,\n",
       " ('it', 1): 11358,\n",
       " ('watched', 1): 2196,\n",
       " ('more', 1): 1089,\n",
       " ('developed', 1): 354,\n",
       " ('taste', 1): 407,\n",
       " ('got', 1): 3235,\n",
       " ('accustomed', 1): 40,\n",
       " ('levels', 1): 290,\n",
       " ('graphic', 1): 259,\n",
       " ('injustice', 1): 54,\n",
       " ('crooked', 1): 55,\n",
       " ('guards', 1): 63,\n",
       " ('wholl', 1): 16,\n",
       " ('sold', 1): 154,\n",
       " ('nickel', 1): 5,\n",
       " ('inmates', 1): 57,\n",
       " ('kill', 1): 915,\n",
       " ('order', 1): 978,\n",
       " ('get', 1): 8211,\n",
       " ('well', 1): 11406,\n",
       " ('mannered', 1): 30,\n",
       " ('middle', 1): 710,\n",
       " ('class', 1): 784,\n",
       " ('turned', 1): 762,\n",
       " ('bitches', 1): 7,\n",
       " ('lack', 1): 755,\n",
       " ('street', 1): 682,\n",
       " ('skills', 1): 232,\n",
       " ('experience', 1): 1379,\n",
       " ('may', 1): 3795,\n",
       " ('become', 1): 1741,\n",
       " ('comfortable', 1): 156,\n",
       " ('uncomfortable', 1): 121,\n",
       " ('viewingthats', 1): 1,\n",
       " ('touch', 1): 579,\n",
       " ('darker', 1): 159,\n",
       " ('side', 1): 1331,\n",
       " ('wonderful', 1): 2641,\n",
       " ('little', 1): 6417,\n",
       " ('production', 1): 1563,\n",
       " ('filming', 1): 352,\n",
       " ('technique', 1): 170,\n",
       " ('unassuming', 1): 20,\n",
       " ('oldtimebbc', 1): 1,\n",
       " ('fashion', 1): 319,\n",
       " ('gives', 1): 1988,\n",
       " ('comforting', 1): 28,\n",
       " ('sometimes', 1): 1384,\n",
       " ('discomforting', 1): 7,\n",
       " ('sense', 1): 2032,\n",
       " ('realism', 1): 347,\n",
       " ('entire', 1): 1189,\n",
       " ('piece', 1): 1266,\n",
       " ('actors', 1): 3939,\n",
       " ('extremely', 1): 1030,\n",
       " ('chosen', 1): 235,\n",
       " ('michael', 1): 1383,\n",
       " ('sheen', 1): 98,\n",
       " ('has', 1): 159,\n",
       " ('polari', 1): 1,\n",
       " ('voices', 1): 239,\n",
       " ('pat', 1): 149,\n",
       " ('too', 1): 1747,\n",
       " ('truly', 1): 2017,\n",
       " ('see', 1): 11986,\n",
       " ('seamless', 1): 32,\n",
       " ('editing', 1): 551,\n",
       " ('guided', 1): 35,\n",
       " ('references', 1): 288,\n",
       " ('williams', 1): 340,\n",
       " ('diary', 1): 60,\n",
       " ('entries', 1): 60,\n",
       " ('worth', 1): 2469,\n",
       " ('terrificly', 1): 4,\n",
       " ('written', 1): 1352,\n",
       " ('performed', 1): 252,\n",
       " ('masterful', 1): 156,\n",
       " ('great', 1): 12810,\n",
       " ('masters', 1): 148,\n",
       " ('comedy', 1): 3362,\n",
       " ('life', 1): 7570,\n",
       " ('really', 1): 10718,\n",
       " ('comes', 1): 2401,\n",
       " ('things', 1): 3633,\n",
       " ('fantasy', 1): 604,\n",
       " ('guard', 1): 152,\n",
       " ('which', 1): 811,\n",
       " ('rather', 1): 2508,\n",
       " ('traditional', 1): 328,\n",
       " ('dream', 1): 701,\n",
       " ('techniques', 1): 183,\n",
       " ('remains', 1): 536,\n",
       " ('solid', 1): 692,\n",
       " ('disappears', 1): 71,\n",
       " ('plays', 1): 2644,\n",
       " ('knowledge', 1): 314,\n",
       " ('senses', 1): 111,\n",
       " ('particularly', 1): 1114,\n",
       " ('concerning', 1): 137,\n",
       " ('orton', 1): 16,\n",
       " ('halliwell', 1): 11,\n",
       " ('sets', 1): 860,\n",
       " ('flat', 1): 266,\n",
       " ('halliwells', 1): 1,\n",
       " ('murals', 1): 1,\n",
       " ('decorating', 1): 7,\n",
       " ('every', 1): 3924,\n",
       " ('surface', 1): 269,\n",
       " ('terribly', 1): 157,\n",
       " ('done', 1): 3009,\n",
       " ('thought', 1): 3110,\n",
       " ('way', 1): 7737,\n",
       " ('spend', 1): 373,\n",
       " ('time', 1): 12123,\n",
       " ('hot', 1): 571,\n",
       " ('summer', 1): 437,\n",
       " ('weekend', 1): 169,\n",
       " ('sitting', 1): 335,\n",
       " ('air', 1): 625,\n",
       " ('conditioned', 1): 15,\n",
       " ('theater', 1): 709,\n",
       " ('lighthearted', 1): 161,\n",
       " ('plot', 1): 4594,\n",
       " ('simplistic', 1): 93,\n",
       " ('dialogue', 1): 1104,\n",
       " ('witty', 1): 359,\n",
       " ('characters', 1): 7299,\n",
       " ('likable', 1): 407,\n",
       " ('even', 1): 9484,\n",
       " ('bread', 1): 72,\n",
       " ('suspected', 1): 61,\n",
       " ('serial', 1): 328,\n",
       " ('killer', 1): 884,\n",
       " ('disappointed', 1): 684,\n",
       " ('realize', 1): 636,\n",
       " ('match', 1): 697,\n",
       " ('point', 1): 2520,\n",
       " ('2', 1): 1516,\n",
       " ('risk', 1): 147,\n",
       " ('addiction', 1): 100,\n",
       " ('proof', 1): 119,\n",
       " ('woody', 1): 139,\n",
       " ('allen', 1): 252,\n",
       " ('still', 1): 6367,\n",
       " ('fully', 1): 471,\n",
       " ('control', 1): 508,\n",
       " ('style', 1): 1668,\n",
       " ('many', 1): 7589,\n",
       " ('us', 1): 4589,\n",
       " ('grown', 1): 222,\n",
       " ('love', 1): 8500,\n",
       " ('id', 1): 1167,\n",
       " ('laughed', 1): 355,\n",
       " ('woodys', 1): 12,\n",
       " ('comedies', 1): 537,\n",
       " ('years', 1): 5403,\n",
       " ('decade', 1): 290,\n",
       " ('ive', 1): 3119,\n",
       " ('impressed', 1): 494,\n",
       " ('scarlet', 1): 38,\n",
       " ('johanson', 1): 5,\n",
       " ('managed', 1): 386,\n",
       " ('tone', 1): 526,\n",
       " ('sexy', 1): 471,\n",
       " ('image', 1): 417,\n",
       " ('jumped', 1): 51,\n",
       " ('average', 1): 563,\n",
       " ('spirited', 1): 102,\n",
       " ('young', 1): 4416,\n",
       " ('woman', 1): 2511,\n",
       " ('crown', 1): 57,\n",
       " ('jewel', 1): 104,\n",
       " ('career', 1): 1018,\n",
       " ('wittier', 1): 5,\n",
       " ('devil', 1): 191,\n",
       " ('wears', 1): 129,\n",
       " ('prada', 1): 5,\n",
       " ('interesting', 1): 2839,\n",
       " ('superman', 1): 149,\n",
       " ('friends', 1): 1973,\n",
       " ('basically', 0): 1135,\n",
       " ('theres', 0): 3762,\n",
       " ('family', 0): 2080,\n",
       " ('little', 0): 5936,\n",
       " ('boy', 0): 1268,\n",
       " ('jake', 0): 102,\n",
       " ('thinks', 0): 495,\n",
       " ('zombie', 0): 802,\n",
       " ('closet', 0): 104,\n",
       " ('parents', 0): 668,\n",
       " ('fighting', 0): 562,\n",
       " ('time', 0): 11837,\n",
       " ('movie', 0): 48519,\n",
       " ('slower', 0): 37,\n",
       " ('soap', 0): 306,\n",
       " ('opera', 0): 319,\n",
       " ('suddenly', 0): 600,\n",
       " ('decides', 0): 497,\n",
       " ('become', 0): 1194,\n",
       " ('rambo', 0): 101,\n",
       " ('kill', 0): 1507,\n",
       " ('ok', 0): 1492,\n",
       " ('first', 0): 8218,\n",
       " ('going', 0): 4579,\n",
       " ('make', 0): 9014,\n",
       " ('film', 0): 35870,\n",
       " ('must', 0): 2935,\n",
       " ('decide', 0): 561,\n",
       " ('thriller', 0): 674,\n",
       " ('drama', 0): 977,\n",
       " ('watchable', 0): 426,\n",
       " ('divorcing', 0): 4,\n",
       " ('arguing', 0): 59,\n",
       " ('like', 0): 21882,\n",
       " ('real', 0): 4171,\n",
       " ('life', 0): 4435,\n",
       " ('totally', 0): 1605,\n",
       " ('ruins', 0): 144,\n",
       " ('expected', 0): 743,\n",
       " ('see', 0): 10654,\n",
       " ('boogeyman', 0): 31,\n",
       " ('similar', 0): 681,\n",
       " ('instead', 0): 2868,\n",
       " ('watched', 0): 2278,\n",
       " ('meaningless', 0): 180,\n",
       " ('spots', 0): 115,\n",
       " ('3', 0): 1843,\n",
       " ('10', 0): 2221,\n",
       " ('well', 0): 7822,\n",
       " ('playing', 0): 1504,\n",
       " ('descent', 0): 99,\n",
       " ('dialogs', 0): 165,\n",
       " ('shots', 0): 1122,\n",
       " ('ignore', 0): 166,\n",
       " ('them', 0): 2601,\n",
       " ('petter', 1): 1,\n",
       " ('matteis', 1): 3,\n",
       " ('money', 1): 1339,\n",
       " ('visually', 1): 307,\n",
       " ('stunning', 1): 600,\n",
       " ('film', 1): 40164,\n",
       " ('watch', 1): 6631,\n",
       " ('mr', 1): 1545,\n",
       " ('mattei', 1): 24,\n",
       " ('offers', 1): 437,\n",
       " ('vivid', 1): 150,\n",
       " ('portrait', 1): 205,\n",
       " ('human', 1): 1983,\n",
       " ('relations', 1): 115,\n",
       " ('movie', 1): 36704,\n",
       " ('seems', 1): 3099,\n",
       " ('telling', 1): 597,\n",
       " ('power', 1): 1042,\n",
       " ('success', 1): 721,\n",
       " ('people', 1): 8473,\n",
       " ('different', 1): 2934,\n",
       " ('situations', 1): 561,\n",
       " ('encounter', 1): 235,\n",
       " ('variation', 1): 48,\n",
       " ('arthur', 1): 371,\n",
       " ('schnitzlers', 1): 2,\n",
       " ('play', 1): 2476,\n",
       " ('theme', 1): 940,\n",
       " ('director', 1): 3437,\n",
       " ('transfers', 1): 15,\n",
       " ('action', 1): 3014,\n",
       " ('present', 1): 679,\n",
       " ('new', 1): 4597,\n",
       " ('york', 1): 866,\n",
       " ('meet', 1): 743,\n",
       " ('connect', 1): 98,\n",
       " ('connected', 1): 137,\n",
       " ('another', 1): 4091,\n",
       " ('next', 1): 1658,\n",
       " ('person', 1): 1458,\n",
       " ('know', 1): 5709,\n",
       " ('previous', 1): 690,\n",
       " ('contact', 1): 172,\n",
       " ('stylishly', 1): 14,\n",
       " ('sophisticated', 1): 155,\n",
       " ('luxurious', 1): 20,\n",
       " ('look', 1): 3705,\n",
       " ('taken', 1): 1065,\n",
       " ('live', 1): 1723,\n",
       " ('world', 1): 4459,\n",
       " ('habitat', 1): 7,\n",
       " ('gets', 1): 2917,\n",
       " ('souls', 1): 161,\n",
       " ('picture', 1): 1604,\n",
       " ('stages', 1): 90,\n",
       " ('loneliness', 1): 139,\n",
       " ('inhabits', 1): 25,\n",
       " ('big', 1): 3365,\n",
       " ('best', 1): 8388,\n",
       " ('place', 1): 2393,\n",
       " ('find', 1): 4452,\n",
       " ('sincere', 1): 119,\n",
       " ('fulfillment', 1): 32,\n",
       " ('discerns', 1): 1,\n",
       " ('case', 1): 1349,\n",
       " ('acting', 1): 4690,\n",
       " ('good', 1): 14572,\n",
       " ('direction', 1): 1184,\n",
       " ('steve', 1): 399,\n",
       " ('buscemi', 1): 26,\n",
       " ('rosario', 1): 32,\n",
       " ('dawson', 1): 76,\n",
       " ('carol', 1): 145,\n",
       " ('kane', 1): 171,\n",
       " ('imperioli', 1): 15,\n",
       " ('adrian', 1): 57,\n",
       " ('grenier', 1): 2,\n",
       " ('rest', 1): 1413,\n",
       " ('talented', 1): 586,\n",
       " ('cast', 1): 4049,\n",
       " ('make', 1): 6314,\n",
       " ('come', 1): 3102,\n",
       " ('alive', 1): 514,\n",
       " ('wish', 1): 992,\n",
       " ('luck', 1): 246,\n",
       " ('await', 1): 31,\n",
       " ('anxiously', 1): 12,\n",
       " ('work', 1): 4326,\n",
       " ('probably', 1): 2659,\n",
       " ('alltime', 1): 154,\n",
       " ('favorite', 1): 1833,\n",
       " ('story', 1): 12611,\n",
       " ('selflessness', 1): 3,\n",
       " ('sacrifice', 1): 126,\n",
       " ('dedication', 1): 63,\n",
       " ('noble', 1): 155,\n",
       " ('cause', 1): 505,\n",
       " ('preachy', 1): 70,\n",
       " ('boring', 1): 640,\n",
       " ('old', 1): 3947,\n",
       " ('despite', 1): 1428,\n",
       " ('seen', 1): 6707,\n",
       " ('15', 1): 371,\n",
       " ('times', 1): 3507,\n",
       " ('last', 1): 3013,\n",
       " ('25', 1): 178,\n",
       " ('paul', 1): 890,\n",
       " ('lukas', 1): 46,\n",
       " ('performance', 1): 3639,\n",
       " ('brings', 1): 814,\n",
       " ('tears', 1): 433,\n",
       " ('eyes', 1): 1289,\n",
       " ('bette', 1): 149,\n",
       " ('davis', 1): 362,\n",
       " ('sympathetic', 1): 281,\n",
       " ('roles', 1): 1283,\n",
       " ('delight', 1): 247,\n",
       " ('kids', 1): 1818,\n",
       " ('are', 1): 594,\n",
       " ('grandma', 1): 36,\n",
       " ('says', 1): 1076,\n",
       " ('like', 1): 17181,\n",
       " ('dressedup', 1): 1,\n",
       " ('midgets', 1): 7,\n",
       " ('children', 1): 1546,\n",
       " ('makes', 1): 4695,\n",
       " ('fun', 1): 3241,\n",
       " ('mothers', 1): 196,\n",
       " ('slow', 1): 822,\n",
       " ('awakening', 1): 45,\n",
       " ('whats', 1): 669,\n",
       " ('happening', 1): 329,\n",
       " ('roof', 1): 89,\n",
       " ('believable', 1): 918,\n",
       " ('startling', 1): 82,\n",
       " ('dozen', 1): 145,\n",
       " ('thumbs', 1): 131,\n",
       " ('theyd', 1): 98,\n",
       " ('up', 1): 1416,\n",
       " ('sure', 1): 2461,\n",
       " ('resurrection', 1): 16,\n",
       " ('dated', 1): 305,\n",
       " ('seahunt', 1): 2,\n",
       " ('series', 1): 3876,\n",
       " ('tech', 1): 40,\n",
       " ('today', 1): 1462,\n",
       " ('bring', 1): 878,\n",
       " ('back', 1): 4801,\n",
       " ('kid', 1): 954,\n",
       " ('excitement', 1): 192,\n",
       " ('mei', 1): 16,\n",
       " ('grew', 1): 293,\n",
       " ('black', 1): 1954,\n",
       " ('white', 1): 1287,\n",
       " ('tv', 1): 2792,\n",
       " ('gunsmoke', 1): 15,\n",
       " ('heros', 1): 70,\n",
       " ('weekyou', 1): 1,\n",
       " ('vote', 1): 227,\n",
       " ('comeback', 1): 56,\n",
       " ('sea', 1): 334,\n",
       " ('huntwe', 1): 1,\n",
       " ('need', 1): 1671,\n",
       " ('change', 1): 1044,\n",
       " ('pace', 1): 641,\n",
       " ('water', 1): 576,\n",
       " ('adventureoh', 1): 1,\n",
       " ('thank', 1): 449,\n",
       " ('outlet', 1): 19,\n",
       " ('view', 1): 1124,\n",
       " ('viewpoints', 1): 20,\n",
       " ('moviesso', 1): 2,\n",
       " ('ole', 1): 17,\n",
       " ('believe', 1): 2090,\n",
       " ('wan', 1): 117,\n",
       " ('na', 1): 274,\n",
       " ('saywould', 1): 1,\n",
       " ('nice', 1): 2119,\n",
       " ('read', 1): 1676,\n",
       " ('plus', 1): 608,\n",
       " ('points', 1): 690,\n",
       " ('huntif', 1): 1,\n",
       " ('rhymes', 1): 9,\n",
       " ('10', 1): 2106,\n",
       " ('lines', 1): 1249,\n",
       " ('let', 1): 1464,\n",
       " ('submitor', 1): 1,\n",
       " ('leave', 1): 1071,\n",
       " ('doubt', 1): 710,\n",
       " ('quitif', 1): 1,\n",
       " ('must', 1): 3232,\n",
       " ('lets', 1): 771,\n",
       " ('show', 0): 5719,\n",
       " ('amazing', 0): 510,\n",
       " ('fresh', 0): 237,\n",
       " ('innovative', 0): 82,\n",
       " ('idea', 0): 2598,\n",
       " ('70s', 0): 524,\n",
       " ('aired', 0): 102,\n",
       " ('7', 0): 342,\n",
       " ('8', 0): 312,\n",
       " ('years', 0): 3408,\n",
       " ('brilliant', 0): 534,\n",
       " ('things', 0): 3674,\n",
       " ('dropped', 0): 146,\n",
       " ('that', 0): 3481,\n",
       " ('1990', 0): 66,\n",
       " ('really', 0): 12293,\n",
       " ('funny', 0): 4506,\n",
       " ('anymore', 0): 367,\n",
       " ('continued', 0): 112,\n",
       " ('decline', 0): 61,\n",
       " ('complete', 0): 1288,\n",
       " ('waste', 0): 2601,\n",
       " ('today', 0): 479,\n",
       " ('truly', 0): 1441,\n",
       " ('disgraceful', 0): 34,\n",
       " ('far', 0): 3224,\n",
       " ('fallen', 0): 149,\n",
       " ('writing', 0): 1497,\n",
       " ('painfully', 0): 323,\n",
       " ('bad', 0): 14362,\n",
       " ('performances', 0): 1121,\n",
       " ('almost', 0): 3123,\n",
       " ('mildly', 0): 298,\n",
       " ('entertaining', 0): 1162,\n",
       " ('respite', 0): 9,\n",
       " ('guesthosts', 0): 1,\n",
       " ('probably', 0): 2924,\n",
       " ('still', 0): 4386,\n",
       " ('air', 0): 598,\n",
       " ('find', 0): 3743,\n",
       " ('hard', 0): 2513,\n",
       " ('believe', 0): 2869,\n",
       " ('creator', 0): 76,\n",
       " ('handselected', 0): 1,\n",
       " ('original', 0): 3645,\n",
       " ('cast', 0): 3204,\n",
       " ('also', 0): 7130,\n",
       " ('chose', 0): 219,\n",
       " ('band', 0): 426,\n",
       " ('hacks', 0): 45,\n",
       " ('followed', 0): 337,\n",
       " ('one', 0): 25186,\n",
       " ('recognize', 0): 158,\n",
       " ('brilliance', 0): 71,\n",
       " ('fit', 0): 481,\n",
       " ('replace', 0): 81,\n",
       " ('mediocrity', 0): 84,\n",
       " ('felt', 0): 1591,\n",
       " ('give', 0): 3651,\n",
       " ('2', 0): 2924,\n",
       " ('stars', 0): 1461,\n",
       " ('respect', 0): 450,\n",
       " ('made', 0): 8472,\n",
       " ('huge', 0): 1055,\n",
       " ('success', 0): 433,\n",
       " ('now', 0): 1217,\n",
       " ('awful', 0): 3007,\n",
       " ('cant', 0): 4471,\n",
       " ('encouraged', 0): 33,\n",
       " ('positive', 0): 611,\n",
       " ('comments', 0): 768,\n",
       " ('looking', 0): 2650,\n",
       " ('forward', 0): 677,\n",
       " ('watching', 0): 5310,\n",
       " ('mistake', 0): 496,\n",
       " ('ive', 0): 3506,\n",
       " ('seen', 0): 6557,\n",
       " ('950', 0): 6,\n",
       " ('films', 0): 6949,\n",
       " ('worst', 0): 4836,\n",
       " ('every', 0): 4011,\n",
       " ('way', 0): 7627,\n",
       " ('editing', 0): 934,\n",
       " ('pacing', 0): 333,\n",
       " ('storyline', 0): 907,\n",
       " ('acting', 0): 7906,\n",
       " ('soundtrack', 0): 629,\n",
       " ('the', 0): 4748,\n",
       " ('song', 0): 793,\n",
       " ('lame', 0): 1195,\n",
       " ('country', 0): 709,\n",
       " ('tune', 0): 130,\n",
       " ('played', 0): 2033,\n",
       " ('less', 0): 1913,\n",
       " ('four', 0): 850,\n",
       " ('times', 0): 2768,\n",
       " ('looks', 0): 2895,\n",
       " ('cheap', 0): 1374,\n",
       " ('nasty', 0): 367,\n",
       " ('boring', 0): 2940,\n",
       " ('extreme', 0): 333,\n",
       " ('rarely', 0): 269,\n",
       " ('happy', 0): 679,\n",
       " ('end', 0): 5642,\n",
       " ('credits', 0): 789,\n",
       " ('thing', 0): 5702,\n",
       " ('prevents', 0): 35,\n",
       " ('giving', 0): 826,\n",
       " ('1score', 0): 1,\n",
       " ('harvey', 0): 79,\n",
       " ('keitel', 0): 42,\n",
       " ('best', 0): 4040,\n",
       " ('performance', 0): 1881,\n",
       " ('least', 0): 3956,\n",
       " ('seems', 0): 3965,\n",
       " ('making', 0): 2825,\n",
       " ('bit', 0): 2600,\n",
       " ('effort', 0): 993,\n",
       " ('obsessives', 0): 2,\n",
       " ('only', 0): 241,\n",
       " ('original', 1): 2619,\n",
       " ('gut', 1): 49,\n",
       " ('wrenching', 1): 55,\n",
       " ('laughter', 1): 231,\n",
       " ('hell', 1): 824,\n",
       " ('mom', 1): 322,\n",
       " ('liked', 1): 1790,\n",
       " ('camp', 1): 442,\n",
       " ('phil', 0): 78,\n",
       " ('alien', 0): 595,\n",
       " ('quirky', 0): 141,\n",
       " ('humour', 0): 396,\n",
       " ('based', 0): 1223,\n",
       " ('around', 0): 3816,\n",
       " ('oddness', 0): 11,\n",
       " ('everything', 0): 2386,\n",
       " ('rather', 0): 2753,\n",
       " ('actual', 0): 831,\n",
       " ('punchlines', 0): 18,\n",
       " ('odd', 0): 526,\n",
       " ('pretty', 0): 4226,\n",
       " ('progressed', 0): 47,\n",
       " ('jokes', 0): 1210,\n",
       " ('low', 0): 1746,\n",
       " ('budget', 0): 2015,\n",
       " ('thats', 0): 4414,\n",
       " ('never', 0): 6590,\n",
       " ('problem', 0): 1815,\n",
       " ('itself', 0): 526,\n",
       " ('interesting', 0): 3279,\n",
       " ('characters', 0): 7600,\n",
       " ('eventually', 0): 619,\n",
       " ('lost', 0): 1390,\n",
       " ('interest', 0): 1058,\n",
       " ('imagine', 0): 843,\n",
       " ('would', 0): 13653,\n",
       " ('appeal', 0): 432,\n",
       " ('stoner', 0): 32,\n",
       " ('currently', 0): 106,\n",
       " ('partaking', 0): 4,\n",
       " ('something', 0): 5708,\n",
       " ('better', 0): 6654,\n",
       " ('try', 0): 2031,\n",
       " ('brother', 0): 805,\n",
       " ('another', 0): 4428,\n",
       " ('planet', 0): 416,\n",
       " ('saw', 0): 2860,\n",
       " ('12', 0): 564,\n",
       " ('came', 0): 1589,\n",
       " ('out', 0): 1892,\n",
       " ('recall', 0): 201,\n",
       " ('scariest', 0): 40,\n",
       " ('scene', 0): 5671,\n",
       " ('big', 0): 3328,\n",
       " ('bird', 0): 120,\n",
       " ('eating', 0): 270,\n",
       " ('men', 0): 1578,\n",
       " ('dangling', 0): 27,\n",
       " ('helplessly', 0): 16,\n",
       " ('parachutes', 0): 2,\n",
       " ('right', 0): 3127,\n",
       " ('horror', 0): 3884,\n",
       " ('young', 0): 2530,\n",
       " ('kid', 0): 1224,\n",
       " ('cheesy', 0): 848,\n",
       " ('b', 0): 726,\n",
       " ('saturday', 0): 212,\n",
       " ('afternoons', 0): 7,\n",
       " ('tired', 0): 482,\n",
       " ('formula', 0): 234,\n",
       " ('monster', 0): 1069,\n",
       " ('type', 0): 1003,\n",
       " ('movies', 0): 8505,\n",
       " ('usually', 0): 1037,\n",
       " ('included', 0): 258,\n",
       " ('hero', 0): 1010,\n",
       " ('beautiful', 0): 1160,\n",
       " ('woman', 0): 2446,\n",
       " ('might', 0): 3301,\n",
       " ('daughter', 0): 1042,\n",
       " ('professor', 0): 196,\n",
       " ('resolution', 0): 120,\n",
       " ('died', 0): 467,\n",
       " ('care', 0): 1660,\n",
       " ('much', 0): 10014,\n",
       " ('romantic', 0): 511,\n",
       " ('angle', 0): 147,\n",
       " ('year', 0): 1556,\n",
       " ('old', 0): 3844,\n",
       " ('predictable', 0): 1223,\n",
       " ('plots', 0): 326,\n",
       " ('love', 0): 4186,\n",
       " ('unintentional', 0): 176,\n",
       " ('humor', 0): 1176,\n",
       " ('but', 0): 1280,\n",
       " ('later', 0): 1718,\n",
       " ('psycho', 0): 228,\n",
       " ('loved', 0): 676,\n",
       " ('star', 0): 1702,\n",
       " ('janet', 0): 63,\n",
       " ('leigh', 0): 83,\n",
       " ('bumped', 0): 14,\n",
       " ('early', 0): 1273,\n",
       " ('sat', 0): 415,\n",
       " ('took', 0): 1128,\n",
       " ('notice', 0): 383,\n",
       " ('point', 0): 3495,\n",
       " ('since', 0): 2701,\n",
       " ('screenwriters', 0): 99,\n",
       " ('story', 0): 9904,\n",
       " ('scary', 0): 1136,\n",
       " ('possible', 0): 1107,\n",
       " ('wellworn', 0): 15,\n",
       " ('rules', 0): 166,\n",
       " ('im', 0): 5674,\n",
       " ('fan', 0): 1859,\n",
       " ('bolls', 0): 29,\n",
       " ('work', 0): 3890,\n",
       " ('many', 0): 5801,\n",
       " ('are', 0): 629,\n",
       " ('enjoyed', 0): 695,\n",
       " ('postal', 0): 22,\n",
       " ('maybe', 0): 2807,\n",
       " ('boll', 0): 184,\n",
       " ('apparently', 0): 1251,\n",
       " ('bought', 0): 476,\n",
       " ('rights', 0): 156,\n",
       " ('use', 0): 1849,\n",
       " ('cry', 0): 270,\n",
       " ('long', 0): 3195,\n",
       " ('ago', 0): 849,\n",
       " ('even', 0): 15098,\n",
       " ('game', 0): 1159,\n",
       " ('finsished', 0): 1,\n",
       " ('people', 0): 9237,\n",
       " ('killing', 0): 845,\n",
       " ('mercs', 0): 1,\n",
       " ('infiltrating', 0): 6,\n",
       " ('secret', 0): 523,\n",
       " ('research', 0): 273,\n",
       " ('labs', 0): 10,\n",
       " ('located', 0): 67,\n",
       " ('tropical', 0): 37,\n",
       " ('island', 0): 717,\n",
       " ('warned', 0): 244,\n",
       " ('mr', 0): 1195,\n",
       " ('schemed', 0): 1,\n",
       " ('together', 0): 1888,\n",
       " ('along', 0): 1653,\n",
       " ('legion', 0): 21,\n",
       " ('schmucks', 0): 3,\n",
       " ('feeling', 0): 1007,\n",
       " ('loneley', 0): 1,\n",
       " ('set', 0): 2107,\n",
       " ('invites', 0): 51,\n",
       " ('three', 0): 2112,\n",
       " ('countrymen', 0): 6,\n",
       " ('play', 0): 1905,\n",
       " ('with', 0): 1132,\n",
       " ('players', 0): 213,\n",
       " ('go', 0): 5091,\n",
       " ('names', 0): 468,\n",
       " ('til', 0): 40,\n",
       " ('schweiger', 0): 9,\n",
       " ('udo', 0): 23,\n",
       " ('kier', 0): 15,\n",
       " ('ralf', 0): 4,\n",
       " ('moeller', 0): 2,\n",
       " ('actually', 0): 5060,\n",
       " ('selfs', 0): 1,\n",
       " ('biz', 0): 18,\n",
       " ('tale', 0): 463,\n",
       " ('goes', 0): 2476,\n",
       " ('this', 0): 4338,\n",
       " ('jack', 0): 665,\n",
       " ('carver', 0): 21,\n",
       " ('yes', 0): 1533,\n",
       " ('german', 0): 443,\n",
       " ('hail', 0): 33,\n",
       " ('bratwurst', 0): 2,\n",
       " ('dudes', 0): 46,\n",
       " ('however', 0): 3417,\n",
       " ('tils', 0): 1,\n",
       " ('badass', 0): 36,\n",
       " ('complained', 0): 32,\n",
       " ('hes', 0): 3014,\n",
       " ('staying', 0): 114,\n",
       " ('true', 0): 1631,\n",
       " ('whole', 0): 3569,\n",
       " ('agenda', 0): 99,\n",
       " ('person', 0): 1615,\n",
       " ('perspective', 0): 159,\n",
       " ('know', 0): 6671,\n",
       " ('looked', 0): 1392,\n",
       " ('kicking', 0): 95,\n",
       " ('a', 0): 1154,\n",
       " ('beyond', 0): 1067,\n",
       " ('demented', 0): 70,\n",
       " ('evil', 0): 1473,\n",
       " ('mad', 0): 511,\n",
       " ('scientist', 0): 434,\n",
       " ('dr', 0): 724,\n",
       " ('krieger', 0): 2,\n",
       " ('geneticallymutatedsoldiers', 0): 1,\n",
       " ('gms', 0): 3,\n",
       " ('called', 0): 1453,\n",
       " ('performing', 0): 88,\n",
       " ('topsecret', 0): 9,\n",
       " ('reminds', 0): 215,\n",
       " ('spoiler', 0): 501,\n",
       " ('vancouver', 0): 20,\n",
       " ('reason', 0): 2951,\n",
       " ('palm', 0): 47,\n",
       " ('trees', 0): 134,\n",
       " ('here', 0): 2428,\n",
       " ('got', 0): 3977,\n",
       " ('nice', 0): 1686,\n",
       " ('rich', 0): 503,\n",
       " ('lumberjackwoods', 0): 1,\n",
       " ('gone', 0): 808,\n",
       " ('started', 0): 1090,\n",
       " ('mehehe', 0): 1,\n",
       " ('can', 0): 1379,\n",
       " ('not', 0): 2827,\n",
       " ('more', 0): 846,\n",
       " ('wan', 0): 190,\n",
       " ('na', 0): 487,\n",
       " ('stay', 0): 917,\n",
       " ('shenanigans', 0): 27,\n",
       " ('disappointed', 0): 1115,\n",
       " ('delivers', 0): 225,\n",
       " ('experience', 0): 798,\n",
       " ('meaning', 0): 437,\n",
       " ('suck', 0): 279,\n",
       " ('worth', 0): 2171,\n",
       " ('mentioning', 0): 120,\n",
       " ('imply', 0): 44,\n",
       " ('good', 0): 14340,\n",
       " ('areas', 0): 102,\n",
       " ('boat', 0): 319,\n",
       " ('scenes', 0): 5533,\n",
       " ('cromedalbino', 0): 1,\n",
       " ('squad', 0): 111,\n",
       " ('enters', 0): 102,\n",
       " ('makes', 0): 3598,\n",
       " ('laugh', 0): 1647,\n",
       " ('reeks', 0): 46,\n",
       " ('scheisse', 0): 1,\n",
       " ('poop', 0): 38,\n",
       " ('simpletons', 0): 7,\n",
       " ('take', 0): 3528,\n",
       " ('wiff', 0): 2,\n",
       " ('ahead', 0): 347,\n",
       " ('btw', 0): 79,\n",
       " ('gets', 0): 3354,\n",
       " ('annoying', 0): 1538,\n",
       " ('sidekick', 0): 122,\n",
       " ('shoot', 0): 575,\n",
       " ('minutes', 0): 4257,\n",
       " ('screen', 0): 2192,\n",
       " ('shakespeare', 0): 183,\n",
       " ('appreciate', 0): 360,\n",
       " ('trying', 0): 2963,\n",
       " ('bring', 0): 757,\n",
       " ('masses', 0): 72,\n",
       " ('ruin', 0): 213,\n",
       " ('scottish', 0): 65,\n",
       " ('favorite', 0): 539,\n",
       " ('certain', 0): 682,\n",
       " ('rev', 0): 6,\n",
       " ('bowdler', 0): 1,\n",
       " ('hence', 0): 175,\n",
       " ('bowdlerization', 0): 1,\n",
       " ('tried', 0): 1057,\n",
       " ('victorian', 0): 47,\n",
       " ('era', 0): 354,\n",
       " ('words', 0): 902,\n",
       " ('improve', 0): 117,\n",
       " ('perfection', 0): 32,\n",
       " ('write', 0): 859,\n",
       " ('ten', 0): 864,\n",
       " ('lines', 0): 1781,\n",
       " ('text', 0): 160,\n",
       " ('and', 0): 2852,\n",
       " ('english', 0): 821,\n",
       " ('composition', 0): 35,\n",
       " ('forte', 0): 18,\n",
       " ('keep', 0): 1528,\n",
       " ('say', 0): 5865,\n",
       " ('saying', 0): 1238,\n",
       " ('cut', 0): 1125,\n",
       " ('it', 0): 11996,\n",
       " ('fantastic', 1): 1205,\n",
       " ('three', 1): 2358,\n",
       " ('prisoners', 1): 133,\n",
       " ('famous', 1): 932,\n",
       " ('george', 1): 888,\n",
       " ('clooney', 1): 63,\n",
       " ('im', 1): 3779,\n",
       " ('fan', 1): 1983,\n",
       " ('roll', 1): 268,\n",
       " ('bad', 1): 3627,\n",
       " ('soundtrack', 1): 999,\n",
       " ('the', 1): 5523,\n",
       " ('man', 1): 5980,\n",
       " ('constant', 1): 270,\n",
       " ('sorrow', 1): 64,\n",
       " ('recommand', 1): 1,\n",
       " ('everybody', 1): 417,\n",
       " ('greetings', 1): 20,\n",
       " ('bart', 1): 54,\n",
       " ('kind', 0): 3031,\n",
       " ('drawn', 0): 291,\n",
       " ('erotic', 0): 163,\n",
       " ('realize', 0): 594,\n",
       " ('amateurish', 0): 378,\n",
       " ('unbelievable', 0): 606,\n",
       " ('bits', 0): 336,\n",
       " ('ever', 0): 6436,\n",
       " ('sort', 0): 1697,\n",
       " ('high', 0): 1920,\n",
       " ('school', 0): 1649,\n",
       " ('project', 0): 641,\n",
       " ('rosanna', 0): 30,\n",
       " ('arquette', 0): 59,\n",
       " ('thinking', 0): 1404,\n",
       " ('stock', 0): 388,\n",
       " ('bizarre', 0): 515,\n",
       " ('supposed', 0): 2244,\n",
       " ('midwest', 0): 12,\n",
       " ('town', 0): 1084,\n",
       " ('get', 0): 10034,\n",
       " ('involved', 0): 1120,\n",
       " ('lessons', 0): 115,\n",
       " ('learned', 0): 240,\n",
       " ('insights', 0): 42,\n",
       " ('stilted', 0): 137,\n",
       " ('quite', 0): 3115,\n",
       " ('ridiculous', 0): 1511,\n",
       " ('lots', 0): 812,\n",
       " ('skin', 0): 227,\n",
       " ('intrigues', 0): 14,\n",
       " ('you', 0): 1958,\n",
       " ('videotaped', 0): 12,\n",
       " ('nonsensewhat', 0): 1,\n",
       " ('bisexual', 0): 22,\n",
       " ('relationship', 0): 660,\n",
       " ('nowhere', 0): 624,\n",
       " ('heterosexual', 0): 24,\n",
       " ('encounters', 0): 111,\n",
       " ('absurd', 0): 385,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spliting data for training and testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Naive bayes is an algorithm that could be used for sentiment analysis. It takes a short time to train and also has a short prediction time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So how do you train a Naive Bayes classifier?\n",
    "- The first part of training a naive bayes classifier is to identify the number of classes that you have.\n",
    "- You will create a probability for each class.\n",
    "$P(D_{pos})$ is the probability that the document is positive.\n",
    "$P(D_{neg})$ is the probability that the document is negative.\n",
    "Use the formulas as follows and store the values in a dictionary:\n",
    "\n",
    "$$P(D_{pos}) = \\frac{D_{pos}}{D}\\tag{1}$$\n",
    "\n",
    "$$P(D_{neg}) = \\frac{D_{neg}}{D}\\tag{2}$$\n",
    "\n",
    "Where $D$ is the total number of documents, or tweets in this case, $D_{pos}$ is the total number of positive tweets and $D_{neg}$ is the total number of negative tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior and Logprior\n",
    "\n",
    "The prior probability represents the underlying probability in the target population that a tweet is positive versus negative.  In other words, if we had no specific information and blindly picked a tweet out of the population set, what is the probability that it will be positive versus that it will be negative? That is the \"prior\".\n",
    "\n",
    "The prior is the ratio of the probabilities $\\frac{P(D_{pos})}{P(D_{neg})}$.\n",
    "We can take the log of the prior to rescale it, and we'll call this the logprior\n",
    "\n",
    "$$\\text{logprior} = log \\left( \\frac{P(D_{pos})}{P(D_{neg})} \\right) = log \\left( \\frac{D_{pos}}{D_{neg}} \\right)$$.\n",
    "\n",
    "Note that $log(\\frac{A}{B})$ is the same as $log(A) - log(B)$.  So the logprior can also be calculated as the difference between two logs:\n",
    "\n",
    "$$\\text{logprior} = \\log (P(D_{pos})) - \\log (P(D_{neg})) = \\log (D_{pos}) - \\log (D_{neg})\\tag{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive and Negative Probability of a Word\n",
    "To compute the positive probability and the negative probability for a specific word in the vocabulary, we'll use the following inputs:\n",
    "\n",
    "- $freq_{pos}$ and $freq_{neg}$ are the frequencies of that specific word in the positive or negative class. In other words, the positive frequency of a word is the number of times the word is counted with the label of 1.\n",
    "- $N_{pos}$ and $N_{neg}$ are the total number of positive and negative words for all documents (for all tweets), respectively.\n",
    "- $V$ is the number of unique words in the entire set of documents, for all classes, whether positive or negative.\n",
    "\n",
    "We'll use these to compute the positive and negative probability for a specific word using this formula:\n",
    "\n",
    "$$ P(W_{pos}) = \\frac{freq_{pos} + 1}{N_{pos} + V}\\tag{4} $$\n",
    "$$ P(W_{neg}) = \\frac{freq_{neg} + 1}{N_{neg} + V}\\tag{5} $$\n",
    "\n",
    "Notice that we add the \"+1\" in the numerator for additive smoothing.  This [wiki article](https://en.wikipedia.org/wiki/Additive_smoothing) explains more about additive smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log likelihood\n",
    "To compute the loglikelihood of that very same word, we can implement the following equations:\n",
    "\n",
    "$$\\text{loglikelihood} = \\log \\left(\\frac{P(W_{pos})}{P(W_{neg})} \\right)\\tag{6}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(result, train_x, train_y):\n",
    "    '''\n",
    "    Input:\n",
    "        result: dictionary from (word, label) to how often the word appears\n",
    "        train_x: a list of reviews\n",
    "        train_y: a list of labels correponding to the reviews (0,1)\n",
    "    Output:\n",
    "        logprior: the log prior. (equation 3 above)\n",
    "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
    "    '''\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "    # calculate V, the number of unique words in the vocabulary\n",
    "    vocab = set([pair[0] for pair in result.keys()])\n",
    "    V = len(vocab)\n",
    "\n",
    "    # calculate N_pos and N_neg\n",
    "    N_pos = N_neg = V_pos = V_neg = 0\n",
    "    for pair in result.keys():\n",
    "        # if the label is positive (greater than zero)\n",
    "        if pair[1] > 0:\n",
    "            \n",
    "            V_pos += 1\n",
    "\n",
    "            # Increment the number of positive words by the count for this (word, label) pair\n",
    "            N_pos += result[pair]\n",
    "\n",
    "        # else, the label is negative\n",
    "        else:\n",
    "            \n",
    "            V_neg += 1\n",
    "\n",
    "            # increment the number of negative words by the count for this (word,label) pair\n",
    "            N_neg += result[pair]\n",
    "\n",
    "    # Calculate D, the number of documents\n",
    "    D = len(train_y)\n",
    "\n",
    "    # Calculate D_pos, the number of positive documents\n",
    "    D_pos = (len(list(filter(lambda x: x > 0, train_y))))\n",
    "\n",
    "    # Calculate D_neg, the number of negative documents \n",
    "    D_neg = (len(list(filter(lambda x: x <= 0, train_y))))\n",
    "\n",
    "    # Calculate logprior\n",
    "    logprior = np.log(D_pos) - np.log(D_neg)\n",
    "\n",
    "    # For each word in the vocabulary...\n",
    "    for word in vocab:\n",
    "        # get the positive and negative frequency of the word\n",
    "        freq_pos = lookup(freqs,word,1)\n",
    "        freq_neg = lookup(freqs,word,0)\n",
    "\n",
    "        # calculate the probability that each word is positive, and negative\n",
    "        p_w_pos = (freq_pos + 1)/(N_pos + V) \n",
    "        p_w_neg = (freq_neg + 1)/(N_neg + V)\n",
    "\n",
    "        # calculate the log likelihood of the word\n",
    "        loglikelihood[word] = np.log(p_w_pos/p_w_neg)\n",
    "\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0016888892903299535\n",
      "167564\n"
     ]
    }
   ],
   "source": [
    "logprior, loglikelihood = train_naive_bayes(freqs, X_train, y_train)\n",
    "print(logprior)\n",
    "print(len(loglikelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For prediction of single review**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(review, logprior, loglikelihood):\n",
    "    '''\n",
    "    Input:\n",
    "        review : a string\n",
    "        logprior: a number\n",
    "        loglikelihood: a dictionary of words mapping to numbers\n",
    "    Output:\n",
    "        p: the sum of all the logliklihoods of each word in the tweet (if found in the dictionary) + logprior (a number)\n",
    "\n",
    "    '''\n",
    "    word_l = review\n",
    "\n",
    "    # initialize probability to zero\n",
    "    p = 0\n",
    "\n",
    "    # add the logprior\n",
    "    p += logprior\n",
    "\n",
    "    for word in word_l:\n",
    "\n",
    "        # check if the word exists in the loglikelihood dictionary\n",
    "        if word in loglikelihood:\n",
    "            # add the log likelihood of that word to the probability\n",
    "            p += loglikelihood[word]\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing on a single review**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(review):\n",
    "    '''\n",
    "    Input:\n",
    "        review: a string containing a review\n",
    "    Output:\n",
    "        review_clean: a list of words containing the processed review\n",
    "\n",
    "    '''\n",
    "    stopwords_english = stopwords.words('english')\n",
    "\n",
    "    review = review.lower()\n",
    "    \n",
    "    #tokenize\n",
    "    review_tokens = word_tokenize(review)\n",
    "    \n",
    "    review_clean = []\n",
    "    for word in review_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "            word not in string.punctuation):  # remove punctuation\n",
    "                review_clean.append(word)\n",
    "\n",
    "    return review_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting single review**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_review = \"Wow this movie was so bad. Felt like I wasted my 2 hours. It started okay then as the time passed it got worse and worse. Casting was so bad and I don't think actors in this movie know how to act.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.226731731480768"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = preprocess(my_review)\n",
    "naive_bayes_predict(a, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Succefully predicted review as of negative sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        test_x: A list of reviews\n",
    "        test_y: the corresponding labels for the list of reviews\n",
    "        logprior: the logprior\n",
    "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
    "    Output:\n",
    "        accuracy: (# of reviews classified correctly)/(total # of reviews)\n",
    "    \"\"\"\n",
    "    accuracy = 0 \n",
    "\n",
    "    y_hats = []\n",
    "    for tweet in test_x:\n",
    "        # if the prediction is > 0\n",
    "        if naive_bayes_predict(tweet, logprior, loglikelihood) > 0:\n",
    "            # the predicted class is 1\n",
    "            y_hat_i = 1\n",
    "        else:\n",
    "            # otherwise the predicted class is 0\n",
    "            y_hat_i = 0\n",
    "\n",
    "        # append the predicted class to the list y_hats\n",
    "        y_hats.append(y_hat_i)\n",
    "\n",
    "    # error is the average of the absolute values of the differences between y_hats and test_y\n",
    "    error = np.mean(np.absolute(y_hats-test_y))\n",
    "\n",
    "    # Accuracy is 1 minus the error\n",
    "    accuracy = 1-error\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9154"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_naive_bayes(X_test, y_test, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
